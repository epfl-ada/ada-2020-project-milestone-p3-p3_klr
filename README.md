# **Milestone P3: Team KLR**


# **FIRST DRAFT**


## **1) Title** : Boosting instead of bagging


## **2) Abstract**

While the paper explores the predictive accuracy of Random Forest, we propose to study a more recent alternative to Random Forest: Boosted Decision Trees. The motivation behind this project is to explore through application what has been seen in class concerning Random Forest VS Boosted Decision Trees (lecture 7, slides 55-58). Furthermore, according to some researchs on the web, Gradient Boosting performs well on unbalanced data (ex: real time risk assessment) whereas Random Forest performs well on multi-class problems having a lot of statistical noise.
As a result, we would like to extend the analysis from the paper by implementing this new method (which might also consolidates the results found by the researchers concerning the variables importance in Civil War Onset). The story we would like to investigate is whether Boosted Decision Trees handles this Class-Imbalanced Civil War Onset Data better and to offer a new way to better predict these destructive events.


## **3) Research Questions**

- Are the variables importance in Civil War Onset the sames? (consolidate previous findings)
- Is there additional variables that come into play? (enhance our understanding of Civil War Onset)
- Can it better handle this unbalanced data? (better predictive accuracy to prevent these destructive events from happening)


## **4) Proposed dataset**

Concerning the dataset to use, we will keep using the same as the researchers did. Indeed, the goal here is to compare the predictive accuracy of both Random Forest and Gradient Boosting after having implemented the latter. 

*Maybe add more things in this part*

## **5) Methods**

*I'm waiting for your feedbacks to write this*

## **6) Proposed timeline**

The project is due for December 18th, giving us 3 weeks to complete the work. This is why we decided to split the work into 3 milestones:

- **December 4th**: Implement Gradient Boosting
- **December 11th**: Evaluate prediction accuracy and variable importance
- **December 18th**: Clean up the code, prepare the report and the short presentation movie

*Add the sketch of the planning, and maybe also more detailed things such as how we split the work among us, ect...*

## **7) Questions for TAs (optional)**

- Libraries to use?
- Heuristics?





# **Assignment**

## **1) Title**

#### *To Do*
*Find a title to our project extension*

## **2) Abstract**

#### *To Do*
*A 150 word description of the project idea, goals, datasets used. What's the motivation behind your project? How do you propose to extend the analysis from the paper? What story would you like to tell, and why?*

## **3) Research Questions**

#### *To Do*
*A list of research questions you would like to address during the project.*

## **4) Proposed dataset**

#### *To Do*
*List the dataset(s) you want to use, and some ideas on how you expect to get, manage, process, and enrich it/them. Show us that you've read the docs and some examples, and that you have a clear idea on what to expect. Discuss data size and format if relevant. It is your responsibility to check that what you propose is feasible given the datasets at hand.*

## **5) Methods**

#### *To Do*
*Similarly to how me explained the methods in Milestone P1*

## **6) Proposed timeline**

#### *To Do*
*Organization within the team. A list of internal milestones up until project milestone P4. Add here a sketch of your planning for the next project milestone.*

## **7) Questions for TAs (optional)**

#### *To Do*
*Add here any questions you have for us related to the proposed project.*
