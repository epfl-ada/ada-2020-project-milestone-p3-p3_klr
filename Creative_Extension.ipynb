{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone P3: Team KLR - Extending the comparison of classification models for rare civil war onsets\n",
    "\n",
    "This notebook serves as an extension of Comparing Random Forest with Logistic Regression for Predicting Class-Imbalanced Civil War Onset Data by Muchlinski David, Siroky David, He Jingrui & Kocher Matthew (2016). In similar fashion as Muchlinski et al., 2016, we aim to contribute to the insofar discarded predictive statistical methods in political science, in favor of accurately predicting significant events such as civil wars. To this end, Muchlinski et al., 2016's approach of comparing experimental performance of algorithmic maneuveurs via a multitude of metrics is adopted. However, in contrast with only using Random Forest and near-arbitrarily selecting features, we attempt in our paper to explore and implement additional feature-selection and classification methods through rigorous incorporation of boosting, and a variety of classification algorithms, as well as on and offline feature selection, which benefit an extended, deepened comparison and discussion surrounding not only this imbalanced prediction task, but also the causal estimation of features. While indeed from Muchlinski et al., 2016, it seems that Random Forests drastically outperform their determined competitor in all metrics employed, nuance of their strengths and weaknesses in contrast with more suited models remains uninvestigated, providing justification for extending this analysis.\n",
    "\n",
    "First, we implement on-and-offline feature selection methods building on Muchlisnki' et al's comparison of Fearon and Latin (2003), Collier and Hoeffler (2004), and Hegre and Sambanis (2006). From which we would like to uncover how feature selection methods serve to aid model performance. The .txt file `notes.txt` contains which variables were used originally by Fearon and Latin (2003), Collier and Hoeffler (2004), and Hegre and Sambanis (2006). We first retrieve these and later compare performance with and without arbitrary feature selection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main dataset you have to use is `SambnisImp.csv`.\n",
      "Additionally, the provided `Sambanis Codebook.pdf` file contains a textual\n",
      "description of (most) used variables.\n",
      "\n",
      "---\n",
      "\n",
      "When loading the data for replication purposes, note that the authors only\n",
      "load the following 91 variables:\n",
      "\n",
      "    \"warstds\", \"ager\", \"agexp\", \"anoc\", \"army85\", \"autch98\", \"auto4\",\n",
      "    \"autonomy\", \"avgnabo\", \"centpol3\", \"coldwar\", \"decade1\", \"decade2\",\n",
      "    \"decade3\", \"decade4\", \"dem\", \"dem4\", \"demch98\", \"dlang\", \"drel\", \"durable\",\n",
      "    \"ef\", \"ef2\", \"ehet\", \"elfo\", \"elfo2\", \"etdo4590\", \"expgdp\", \"exrec\",\n",
      "    \"fedpol3\", \"fuelexp\", \"gdpgrowth\", \"geo1\", \"geo2\", \"geo34\", \"geo57\",\n",
      "    \"geo69\", \"geo8\", \"illiteracy\", \"incumb\", \"infant\", \"inst\", \"inst3\", \"life\",\n",
      "    \"lmtnest\", \"ln_gdpen\", \"lpopns\", \"major\", \"manuexp\", \"milper\", \"mirps0\",\n",
      "    \"mirps1\", \"mirps2\", \"mirps3\", \"nat_war\", \"ncontig\", \"nmgdp\", \"nmdp4_alt\",\n",
      "    \"numlang\", \"nwstate\", \"oil\", \"p4mchg\", \"parcomp\", \"parreg\", \"part\",\n",
      "    \"partfree\", \"plural\", \"plurrel\", \"pol4\", \"pol4m\", \"pol4sq\", \"polch98\",\n",
      "    \"polcomp\", \"popdense\", \"presi\", \"pri\", \"proxregc\", \"ptime\", \"reg\",\n",
      "    \"regd4_alt\", \"relfrac\", \"seceduc\", \"second\", \"semipol3\", \"sip2\", \"sxpnew\",\n",
      "    \"sxpsq\", \"tnatwar\", \"trade\", \"warhist\", \"xconst\"\n",
      "\n",
      "(For later tasks or for your own curiosity, it might make sense to leverage the rest of the data as well!)\n",
      "\n",
      "---\n",
      "\n",
      "The 3 logistic regression models the authors replicate in their paper, and that\n",
      "you will have to replicate as well, make use of the following features to\n",
      "predict the target:\n",
      "\n",
      "- Fearon and Laitin (2003): \"warhist\", \"ln_gdpen\", \"lpopns\", \"lmtnest\",\n",
      "    \"ncontig\", \"oil\", \"nwstate\", \"inst3\", \"pol4\", \"ef\", \"relfrac\".\n",
      "\n",
      "- Collier and Hoeffler (2004): \"sxpnew\", \"sxpsq\", \"ln_gdpen\", \"gdpgrowth\",\n",
      "    \"warhist\", \"lmtnest\", \"ef\", \"popdense\", \"lpopns\", \"coldwar\", \"seceduc\",\n",
      "    \"ptime\".\n",
      "\n",
      "- Hegre and Sambanis (2006): \"lpopns\", \"ln_gdpen\", \"inst3\", \"parreg\", \"geo34\",\n",
      "    \"proxregc\", \"gdpgrowth\", \"anoc\", \"partfree\", \"nat_war\", \"lmtnest\",\n",
      "    \"decade1\", \"pol4sq\", \"nwstate\", \"regd4_alt\", \"etdo4590\", \"milper\", \"geo1\",\n",
      "    \"tnatwar\", \"presi\".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat './data/notes.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries, define data path, and other hard-coded variables\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import roc_curve, plot_roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "DATA_PATH = './data/'\n",
    "seed = 7\n",
    "\n",
    "# Extract features used in each paper from notes.txt \n",
    "with open(DATA_PATH+'notes.txt') as f:\n",
    "    \n",
    "    task_notes = f.readlines()\n",
    "    task_notes = ''.join(task_notes)\n",
    "    \n",
    "    fl_feature_names = re.search(r'(?<=Fearon and Laitin \\(2003\\):)[^.\\.]*',task_notes).group()\n",
    "    fl_feature_names = re.sub('\\n|\\s|\\\"','',fl_feature_names).split(',')\n",
    "    \n",
    "    ch_feature_names = re.search(r'(?<=Collier and Hoeffler \\(2004\\):)[^.\\.]*',task_notes).group()\n",
    "    ch_feature_names = re.sub('\\n|\\s|\\\"','',ch_feature_names).split(',')\n",
    "\n",
    "    hs_feature_names = re.search(r'(?<=Hegre and Sambanis \\(2006\\):)[^.\\.]*',task_notes).group()\n",
    "    hs_feature_names = re.sub('\\n|\\s|\\\"','',hs_feature_names).split(',')\n",
    "\n",
    "# load data\n",
    "master_data = pd.read_csv(DATA_PATH+'SambnisImp.csv', index_col='X')\n",
    "\n",
    "# split data into features used for each paper and retrieve regressand \n",
    "y_master = master_data['warstds']\n",
    "\n",
    "fl_x = master_data[fl_feature_names]\n",
    "ch_x = master_data[ch_feature_names]\n",
    "hs_x = master_data[hs_feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
